# Research Agent - Architecture

## ğŸ“Š Project Structure
```
research/
â”œâ”€â”€ README.md                  # Project documentation
â”œâ”€â”€ ARCHITECTURE.md           # This file - how it works
â”œâ”€â”€ __init__.py               # Package initialization
â”œâ”€â”€ agent.py                  # Main ResearchAgent class
â”œâ”€â”€ tools/                    # Research tools
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ tavily_search.py     # Web search tool
â”‚   â”œâ”€â”€ wikipedia_tool.py    # Encyclopedia lookup
â”‚   â””â”€â”€ arxiv_tool.py        # Academic papers
â””â”€â”€ workflows/                # Multi-step workflows
    â”œâ”€â”€ __init__.py
    â””â”€â”€ research_workflow.py  # Orchestration logic
```

## ğŸ”„ How It Works

### 1. User Makes Request
```
User: "Research latest AI developments"
   â†“
```

### 2. Request Goes to ResearchAgent
```
research/agent.py
   â”œâ”€â”€ ResearchAgent.__init__()
   â”‚   â”œâ”€â”€ Loads system prompt: "You are an expert research assistant"
   â”‚   â”œâ”€â”€ Registers 3 tools: Tavily, Wikipedia, arXiv
   â”‚   â””â”€â”€ Connects to OpenAI API
   â”‚
   â””â”€â”€ ResearchAgent.run(query)
       â”œâ”€â”€ Sends query + tools to GPT-4
       â”œâ”€â”€ LLM decides which tools to use
       â””â”€â”€ Returns synthesized results
```

### 3. Tools Are Called (Based on LLM Decision)
```
tools/tavily_search.py
   â””â”€â”€ TavilySearchTool.execute()
       â”œâ”€â”€ Searches current web content
       â”œâ”€â”€ Returns latest news & articles
       â””â”€â”€ Provides source URLs

tools/wikipedia_tool.py
   â””â”€â”€ WikipediaTool.execute()
       â”œâ”€â”€ Looks up encyclopedia entries
       â”œâ”€â”€ Returns factual background
       â””â”€â”€ Provides context

tools/arxiv_tool.py
   â””â”€â”€ ArxivTool.execute()
       â”œâ”€â”€ Searches academic papers
       â”œâ”€â”€ Returns scientific research
       â””â”€â”€ Provides citations
```

### 4. Workflow Orchestration (Optional)
```
workflows/research_workflow.py
   â””â”€â”€ ResearchWorkflow.comprehensive_research()
       â”‚
       Step 1: Web search for current info
       â”œâ”€â”€ agent.run("search latest developments")
       â”‚
       Step 2: Get background from Wikipedia
       â”œâ”€â”€ agent.run("get overview from Wikipedia")
       â”‚
       Step 3: Find academic papers
       â”œâ”€â”€ agent.run("search arXiv papers")
       â”‚
       Step 4: Synthesize all findings
       â””â”€â”€ agent.run("combine and analyze all results")
```

### 5. Response Returns to User
```
   â†“
Result:
   â”œâ”€â”€ Comprehensive research report
   â”œâ”€â”€ Multiple sources cited
   â”œâ”€â”€ Current + Historical context
   â””â”€â”€ Academic backing
```

## ğŸ¯ Data Flow Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  USER   â”‚ "Research AI trends"
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
     â”‚
     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     ResearchAgent (agent.py)            â”‚
â”‚                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚   LLM Router (GPT-4)         â”‚      â”‚
â”‚  â”‚   - Analyzes query           â”‚      â”‚
â”‚  â”‚   - Decides which tools      â”‚      â”‚
â”‚  â”‚   - Combines results         â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚             â”‚                           â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚
â”‚   â”‚                    â”‚               â”‚
â”‚   â–¼                    â–¼               â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚ â”‚ Memory  â”‚      â”‚ Prompt   â”‚         â”‚
â”‚ â”‚ History â”‚      â”‚ Context  â”‚         â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â”‚                                        â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚   â”‚        Tools               â”‚      â”‚
â”‚   â”‚                            â”‚      â”‚
â”‚   â”‚  ğŸ” Tavily Search         â”‚      â”‚
â”‚   â”‚     â†“ Current web data    â”‚      â”‚
â”‚   â”‚                            â”‚      â”‚
â”‚   â”‚  ğŸ“š Wikipedia             â”‚      â”‚
â”‚   â”‚     â†“ Encyclopedia info   â”‚      â”‚
â”‚   â”‚                            â”‚      â”‚
â”‚   â”‚  ğŸ“„ arXiv                 â”‚      â”‚
â”‚   â”‚     â†“ Academic papers     â”‚      â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚
     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ RESULT  â”‚ Comprehensive research report
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ Usage Examples

### Simple Query
```python
from projects.research.agent import ResearchAgent

agent = ResearchAgent()
result = agent.run("What are the latest developments in quantum computing?")
print(result)
```

**Flow:**
1. User query â†’ ResearchAgent
2. Agent â†’ GPT-4 with tools
3. GPT-4 decides â†’ Use Tavily + Wikipedia + arXiv
4. Tools execute â†’ Return data
5. GPT-4 synthesizes â†’ Comprehensive answer
6. Result â†’ User

### Workflow Query
```python
from projects.research.workflows.research_workflow import ResearchWorkflow

workflow = ResearchWorkflow()
result = workflow.comprehensive_research(
    topic="AI Ethics",
    depth="detailed"
)
```

**Flow:**
1. Workflow orchestrates multiple steps
2. Step 1: Web search (Tavily)
3. Step 2: Background (Wikipedia)
4. Step 3: Papers (arXiv)
5. Step 4: Synthesis (GPT-4)
6. Complete report â†’ User

## ğŸ”§ Key Components

### agent.py
- **Purpose:** Main agent class
- **Responsibilities:** 
  - Initialize LLM connection
  - Register tools
  - Handle queries
  - Manage conversation history
- **Key Methods:**
  - `__init__()`: Setup
  - `run(query)`: Execute query
  - `_register_tools()`: Add tools

### tools/
- **Purpose:** External data sources
- **tavily_search.py:** Real-time web search
- **wikipedia_tool.py:** Encyclopedia facts
- **arxiv_tool.py:** Academic research
- **Each tool:**
  - Inherits from `BaseTool`
  - Implements `execute()` method
  - Returns structured data

### workflows/
- **Purpose:** Multi-step orchestration
- **research_workflow.py:** Complex research tasks
- **Features:**
  - Sequential steps
  - Error handling
  - Progress tracking
  - Result combination

## ğŸ’¡ When to Use What

| Task | Use | Why |
|------|-----|-----|
| Quick fact check | `agent.run()` | Single query, fast |
| Current news | Tavily tool | Real-time data |
| Background info | Wikipedia tool | Factual context |
| Academic research | arXiv tool | Scientific papers |
| Comprehensive report | Workflow | Multiple sources + synthesis |
| Comparative analysis | Workflow | Structured multi-step |

## ğŸ” Reflection & Self-Improvement

The Research Agent supports **self-evaluation** to ensure high-quality research outputs:

```python
from projects.research.agent import ResearchAgent

agent = ResearchAgent()

# Run with reflection
result = agent.run_with_reflection(
    "Research latest AI developments",
    auto_improve=True,
    max_iterations=2
)

print(f"Quality Score: {result['reflection']['score']}/10")
print(f"Improvements made: {result['iterations']}")
```

### Reflection Criteria (Research-Specific)
- âœ… **Source diversity:** Multiple credible sources used
- âœ… **Citation accuracy:** Proper attribution and references
- âœ… **Factual correctness:** Information is accurate and verified
- âœ… **Balanced perspective:** Multiple viewpoints considered
- âœ… **Current information:** Up-to-date data and findings

### Example Reflection Output
```python
{
    "score": 8.5,
    "strengths": [
        "Used diverse sources (web, encyclopedia, academic)",
        "Proper citations included",
        "Current information from 2024"
    ],
    "weaknesses": [
        "Could include more academic papers",
        "Missing comparison with classical methods"
    ],
    "improvements": [
        "Add 2-3 more arXiv papers for depth",
        "Include practical applications section"
    ]
}
```

See [REFLECTION.md](../../REFLECTION.md) for complete guide.

## ğŸ“ Technical Details

- **LLM:** OpenAI GPT-4
- **Tools:** 3 (Tavily, Wikipedia, arXiv)
- **Response Time:** 5-15 seconds per query
- **Max Token:** Configurable (default: 4000)
- **Error Handling:** Automatic retry with fallbacks
- **Reflection:** Self-evaluation & auto-improvement supported
